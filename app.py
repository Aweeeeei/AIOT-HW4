import streamlit as st
import pandas as pd
import requests
import feedparser
from newspaper import Article, Config
import jieba
from sumy.parsers.plaintext import PlaintextParser
from sumy.nlp.tokenizers import Tokenizer
from sumy.summarizers.lsa import LsaSummarizer

# --- 1. é é¢è¨­å®š ---
st.set_page_config(page_title="æ–°èæ‘˜è¦åŠ©æ‰‹", page_icon="ğŸ“°", layout="wide")
st.title("ğŸ“° AI æ–°èæœå°‹èˆ‡æ‘˜è¦ (Bing ä¾†æºç©©å®šç‰ˆ)")
st.markdown("ä½¿ç”¨ **Bing News RSS** è§£æ±ºé »ç‡é™åˆ¶å•é¡Œï¼Œæ­é… **LSA æ¼”ç®—æ³•** é€²è¡Œæ¥µé€Ÿæ‘˜è¦ã€‚")

# --- 2. æ ¸å¿ƒåŠŸèƒ½å‡½å¼ ---

def sumy_summarize(text, sentence_count=3):
    """ä½¿ç”¨ Sumy + Jieba é€²è¡Œä¸­æ–‡èƒå–å¼æ‘˜è¦"""
    try:
        if not text: return "ç„¡å…§å®¹"
        
        # ä¸­æ–‡æ–·è©è™•ç†
        seg_list = jieba.cut(text)
        text_segmented = " ".join(seg_list)
        
        # åˆå§‹åŒ–æ‘˜è¦å™¨
        parser = PlaintextParser.from_string(text_segmented, Tokenizer("english")) 
        summarizer = LsaSummarizer() 
        summary_sentences = summarizer(parser.document, sentence_count)
        
        # çµ„åˆçµæœ
        result = ""
        for sentence in summary_sentences:
            raw_sent = str(sentence).replace(" ", "")
            result += raw_sent + "ã€‚"
        return result
    except Exception as e:
        return f"æ‘˜è¦éŒ¯èª¤: {e}"

def extract_and_process(url):
    """
    æŠ“å–ä¸¦æ‘˜è¦
    """
    try:
        # è¨­å®šå½è£ç€è¦½å™¨ User-Agent (é€™æ˜¯çˆ¬èŸ²æˆåŠŸçš„é—œéµ)
        config = Config()
        config.browser_user_agent = 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/115.0.0.0 Safari/537.36'
        config.request_timeout = 10
        
        article = Article(url, config=config)
        article.download()
        article.parse()
        
        # å¦‚æœæ­£æ–‡å¤ªçŸ­ï¼Œæ”¹æŠ“ Meta Description
        if len(article.text) < 50:
             if article.meta_description and len(article.meta_description) > 10:
                 return f"ğŸ“Œ (ä¾†æºç°¡ä»‹) {article.meta_description}"
             return "âš ï¸ ç„¡æ³•æŠ“å–å…§å®¹ (ç¶²ç«™é˜»æ“‹çˆ¬èŸ²)"

        # åŸ·è¡Œæ‘˜è¦
        summary = sumy_summarize(article.text, sentence_count=3)
        return summary
        
    except Exception as e:
        return f"âŒ è™•ç†éŒ¯èª¤: {str(e)}"

def search_bing_rss(keyword, limit=5):
    """
    ä½¿ç”¨ Bing News RSS é€²è¡Œæœå°‹ (æœ€ç©©å®šçš„å… Key æ–¹æ¡ˆ)
    """
    # Bing News RSS URL æ ¼å¼
    # format=rss æŒ‡å®šè¼¸å‡º RSS XML
    rss_url = f"https://www.bing.com/news/search?q={keyword}&format=rss"
    
    # è§£æ RSS
    feed = feedparser.parse(rss_url)
    
    results = []
    # å–å‰ limit ç­†
    for entry in feed.entries[:limit]:
        results.append({
            "title": entry.title,
            "link": entry.link,
            "published": entry.published if 'published' in entry else "Unknown"
        })
        
    return results

# --- 3. ä¸»ç¨‹å¼é‚è¼¯ ---

with st.form(key='search_form'):
    col1, col2 = st.columns([3, 1])
    with col1:
        keyword = st.text_input("è¼¸å…¥é—œéµå­—", placeholder="ä¾‹å¦‚ï¼šOpenAI, å°ç©é›»...")
    with col2:
        submit_button = st.form_submit_button(label='ğŸš€ æœå°‹')

if submit_button and keyword:
    st.divider()
    
    progress_text = st.empty()
    progress_bar = st.progress(0)
    
    progress_text.text(f"ğŸ” æ­£åœ¨é€é Bing æœå°‹ã€Œ{keyword}ã€...")
    
    # æ”¹ç”¨ Bing RSS
    news_items = search_bing_rss(keyword)
    
    if not news_items:
        st.warning("æ‰¾ä¸åˆ°ç›¸é—œæ–°èï¼Œè«‹å˜—è©¦å…¶ä»–é—œéµå­—ã€‚")
        progress_bar.empty()
    else:
        results_data = []
        total = len(news_items)
        
        for i, item in enumerate(news_items):
            progress_text.text(f"æ­£åœ¨è™•ç† ({i+1}/{total}): {item['title']} ...")
            progress_bar.progress((i + 1) / total)
            
            # æŠ“å–ä¸¦æ‘˜è¦
            summary = extract_and_process(item['link'])
            
            results_data.append({
                "æ–°èæ¨™é¡Œ": item['title'],
                "AI é‡é»æ‘˜è¦": summary,
                "é€£çµ": item['link']
            })
        
        progress_bar.empty()
        progress_text.empty()
        
        st.success("âœ… å®Œæˆï¼")
        
        df = pd.DataFrame(results_data)
        st.dataframe(
            df,
            column_config={
                "é€£çµ": st.column_config.LinkColumn("é€£çµ", display_text="ğŸ”— å‰å¾€é–±è®€"),
                "AI é‡é»æ‘˜è¦": st.column_config.TextColumn("AI é‡é»æ‘˜è¦", width="large"),
            },
            hide_index=True,
            use_container_width=True
        )